{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIUdmr9xRQOJ"
   },
   "source": [
    "# Automated Dependency Graph Generation Framework for FDA Medical Device Report\n",
    "# Workflow\n",
    "1. Environment setup\n",
    "2. Transfer text file to Part-of-Speech (POS) tags\n",
    "  - Remember to replace file path.\n",
    "  - The intermetiate POS file will be saved.\n",
    "3. POS to Neo4j Schema\n",
    "  - The Neo4j Schema will be based on the POS file generate on step 2.\n",
    "4. The schema is ready to execute in Neo4j\n",
    "\n",
    "# Tech Stack\n",
    "- spaCy for natural language processing\n",
    "- automate Neo4j Schema generation\n",
    "\n",
    "# Dataset used\n",
    "- FDA Medical Device Report Data (https://www.fda.gov/medical-devices/medical-device-reporting-mdr-how-report-medical-device-problems/mdr-data-files#download) Note that although this script is used on this dataset on medical device, the method could be applied to any text-based documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVbJUqbxRhb8"
   },
   "source": [
    "# 1. Environment setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11172,
     "status": "ok",
     "timestamp": 1740322832470,
     "user": {
      "displayName": "Julie Cheng",
      "userId": "04885444118924469249"
     },
     "user_tz": 300
    },
    "id": "aiCei2tbQpQH",
    "outputId": "c7673809-5b0e-4502-f5d0-213d284e5c8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Downloading spacy-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blis-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: blis, thinc, spacy\n",
      "  Attempting uninstall: blis\n",
      "    Found existing installation: blis 0.7.11\n",
      "    Uninstalling blis-0.7.11:\n",
      "      Successfully uninstalled blis-0.7.11\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.2.5\n",
      "    Uninstalling thinc-8.2.5:\n",
      "      Successfully uninstalled thinc-8.2.5\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.7.5\n",
      "    Uninstalling spacy-3.7.5:\n",
      "      Successfully uninstalled spacy-3.7.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "en-core-web-sm 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.8.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed blis-1.2.0 spacy-3.8.4 thinc-8.3.4\n"
     ]
    }
   ],
   "source": [
    "# not necessary for Colab\n",
    "!pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6859,
     "status": "ok",
     "timestamp": 1740348015388,
     "user": {
      "displayName": "Julie Cheng",
      "userId": "04885444118924469249"
     },
     "user_tz": 300
    },
    "id": "a6htPQn1Rgg7"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 400\n",
    "pd.options.display.max_colwidth =  400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace file paths. (input text file, POS file, output schema file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740322844619,
     "user": {
      "displayName": "Julie Cheng",
      "userId": "04885444118924469249"
     },
     "user_tz": 300
    },
    "id": "HnfJQmVeRkgT"
   },
   "outputs": [],
   "source": [
    "# Modify the file path\n",
    "input_file = \"examples/originaltext_5.txt\"\n",
    "pos_file = \"pos_5.txt\"\n",
    "output_file = \"neo4j_pos_5.cypher\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mikxLf30RxvT"
   },
   "source": [
    "# 2. Transfer text file to Part-of-Speech (POS) tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1740348188388,
     "user": {
      "displayName": "Julie Cheng",
      "userId": "04885444118924469249"
     },
     "user_tz": 300
    },
    "id": "ZmSvGrEE6rcs"
   },
   "outputs": [],
   "source": [
    "def process_sentences_with_heads(input_file, output_file):\n",
    "    # Load spaCy model\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    # Read all sentences from input file\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        # Read lines and filter out empty lines\n",
    "        sentences = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "    # Process the text\n",
    "    doc = nlp(' '.join(sentences))\n",
    "\n",
    "    # Create output\n",
    "    output = []\n",
    "    output.append(\"Token\\tPOS\\tDependency\\tHead_Token\\tHead_Index\")\n",
    "    output.append(\"-\" * 60)\n",
    "\n",
    "    for token in doc:\n",
    "        # Get token's head (parent) information\n",
    "        head_text = token.head.text if token.head != token else \"ROOT\"\n",
    "        head_idx = token.head.i if token.head != token else token.i\n",
    "\n",
    "        output.append(f\"{token.text}\\t{token.pos_}\\t{token.dep_}\\t{head_text}\\t{head_idx}\")\n",
    "\n",
    "        if token.is_sent_end:\n",
    "            output.append(\"\")  # Add blank line between sentences\n",
    "\n",
    "    # Write to file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(output))\n",
    "\n",
    "    print('\\n'.join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1225,
     "status": "ok",
     "timestamp": 1740349887462,
     "user": {
      "displayName": "Julie Cheng",
      "userId": "04885444118924469249"
     },
     "user_tz": 300
    },
    "id": "3MekpCJe63ZE",
    "outputId": "fd696e21-a185-4170-9c6a-abd9bce61416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token\tPOS\tDependency\tHead_Token\tHead_Index\n",
      "------------------------------------------------------------\n",
      "INFORMATION\tPROPN\tcompound\tRECEIVED\t1\n",
      "RECEIVED\tPROPN\tnsubj\tINDICATED\t4\n",
      "BY\tADP\tcompound\tMEDTRONIC\t3\n",
      "MEDTRONIC\tPROPN\tdobj\tRECEIVED\t1\n",
      "INDICATED\tVERB\tROOT\tROOT\t4\n",
      "THAT\tSCONJ\tmark\tPASSED\t8\n",
      ",\tPUNCT\tpunct\tPASSED\t8\n",
      "CUSTOMER\tPROPN\tnsubj\tPASSED\t8\n",
      "PASSED\tVERB\tccomp\tINDICATED\t4\n",
      "AWAY\tADV\tadvmod\tPASSED\t8\n",
      "AT\tADP\tprep\tPASSED\t8\n",
      "HOME\tPROPN\tpobj\tAT\t10\n",
      "ON\tPROPN\tdobj\tPASSED\t8\n",
      "(\tPUNCT\tpunct\tON\t12\n",
      "B)(6\tNOUN\tappos\tON\t12\n",
      ")\tPUNCT\tpunct\t2022\t16\n",
      "2022\tNUM\tappos\tON\t12\n",
      ".\tPUNCT\tpunct\tINDICATED\t4\n",
      "\n",
      "THE\tDET\tdet\tCUSTOMER\t19\n",
      "CUSTOMER\tPROPN\tnsubjpass\tADMITTED\t22\n",
      "WAS\tAUX\tauxpass\tADMITTED\t22\n",
      "NOT\tPART\tneg\tADMITTED\t22\n",
      "ADMITTED\tVERB\tROOT\tROOT\t22\n",
      "TO\tADP\tprep\tADMITTED\t22\n",
      "A\tDET\tdet\tPRIOR\t26\n",
      "HOSPITAL\tNOUN\tcompound\tPRIOR\t26\n",
      "PRIOR\tNOUN\tpobj\tTO\t23\n",
      "TO\tADP\tprep\tPRIOR\t26\n",
      "THE\tDET\tdet\tINCIDENT\t30\n",
      "REPORTED\tPROPN\tcompound\tINCIDENT\t30\n",
      "INCIDENT\tPROPN\tpobj\tTO\t27\n",
      ".\tPUNCT\tpunct\tADMITTED\t22\n",
      "\n",
      "THE\tDET\tdet\tCUSTOMER\t33\n",
      "CUSTOMER\tPROPN\tnsubj\tPASSED\t34\n",
      "PASSED\tVERB\tROOT\tROOT\t34\n",
      "AWAY\tADV\tadvmod\tPASSED\t34\n",
      "IN\tADP\tprep\tPASSED\t34\n",
      "SLEEP\tPROPN\tpobj\tIN\t36\n",
      ".\tPUNCT\tpunct\tPASSED\t34\n",
      "\n",
      "THE\tDET\tdet\tCAUSE\t40\n",
      "CAUSE\tPROPN\tROOT\tROOT\t40\n",
      "FOR\tADP\tprep\tCAUSE\t40\n",
      "DEATH\tNOUN\tpobj\tFOR\t41\n",
      "AND\tCCONJ\tcc\tCAUSE\t40\n",
      "CUSTOMERøS\tVERB\tconj\tCAUSE\t40\n",
      "BLOOD\tNOUN\tcompound\tVALUE\t47\n",
      "GLUCOSE\tPROPN\tcompound\tVALUE\t47\n",
      "VALUE\tNOUN\tnsubj\tWAS\t48\n",
      "WAS\tAUX\tccomp\tCUSTOMERøS\t44\n",
      "UNKNOWN\tADJ\tacomp\tWAS\t48\n",
      ".\tPUNCT\tpunct\tCAUSE\t40\n",
      "\n",
      "THE\tDET\tdet\tCUSTOMER\t52\n",
      "CUSTOMER\tPROPN\tnsubj\tWEARING\t54\n",
      "WAS\tAUX\taux\tWEARING\t54\n",
      "WEARING\tVERB\tROOT\tROOT\t54\n",
      "THE\tDET\tdet\tPUMP\t57\n",
      "INSULIN\tNOUN\tcompound\tPUMP\t57\n",
      "PUMP\tPROPN\tdobj\tWEARING\t54\n",
      "\n",
      "AT\tADP\tROOT\tROOT\t58\n",
      "THE\tDET\tdet\tTIME\t60\n",
      "TIME\tPROPN\tpobj\tAT\t58\n",
      "OF\tADP\tprep\tTIME\t60\n",
      "DEATH\tNOUN\tpobj\tOF\t61\n",
      ".\tPUNCT\tpunct\tAT\t58\n",
      "\n",
      "THE\tDET\tdet\tCUSTOMER\t65\n",
      "CUSTOMER\tPROPN\tnsubj\tUSING\t68\n",
      "WAS\tAUX\taux\tUSING\t68\n",
      "NOT\tPART\tneg\tUSING\t68\n",
      "USING\tVERB\tROOT\tROOT\t68\n",
      "THE\tDET\tdet\tSENSOR\t70\n",
      "SENSOR\tPROPN\tdobj\tUSING\t68\n",
      ".\tPUNCT\tpunct\tUSING\t68\n",
      "\n",
      "THE\tDET\tdet\tPUMP\t74\n",
      "INSULIN\tPROPN\tcompound\tPUMP\t74\n",
      "PUMP\tPROPN\tnsubj\tBE\t77\n",
      "WILL\tAUX\taux\tBE\t77\n",
      "NOT\tPART\tneg\tBE\t77\n",
      "BE\tAUX\tROOT\tROOT\t77\n",
      "RETURNED\tPROPN\tattr\tBE\t77\n",
      "FOR\tADP\tprep\tRETURNED\t78\n",
      "ANALYSIS\tPROPN\tpobj\tFOR\t79\n",
      ".\tPUNCT\tpunct\tBE\t77\n",
      "\n",
      "CURRENTLY\tPROPN\tnpadvmod\tIS\t84\n",
      "IT\tPRON\tnsubj\tIS\t84\n",
      "IS\tAUX\tROOT\tROOT\t84\n",
      "UNKNOWN\tADJ\tacomp\tIS\t84\n",
      "WHETHER\tSCONJ\tmark\tCAUSED\t93\n",
      "OR\tCCONJ\tcc\tWHETHER\t86\n",
      "NOT\tPART\tneg\tHAVE\t92\n",
      "THE\tDET\tdet\tDEVICE\t90\n",
      "DEVICE\tNOUN\tnsubj\tHAVE\t92\n",
      "MAY\tAUX\taux\tHAVE\t92\n",
      "HAVE\tAUX\taux\tCAUSED\t93\n",
      "CAUSED\tVERB\tccomp\tIS\t84\n",
      "OR\tCCONJ\tcc\tCAUSED\t93\n",
      "CONTRIBUTED\tVERB\tconj\tCAUSED\t93\n",
      "TO\tADP\tprep\tCONTRIBUTED\t95\n",
      "THE\tDET\tdet\tEVENT\t98\n",
      "EVENT\tNOUN\tpobj\tTO\t96\n",
      "\n",
      "AS\tSCONJ\tmark\tBEEN\t103\n",
      "NO\tDET\tdet\tPRODUCT\t101\n",
      "PRODUCT\tNOUN\tnsubj\tBEEN\t103\n",
      "HAS\tAUX\taux\tBEEN\t103\n",
      "BEEN\tAUX\tROOT\tROOT\t103\n",
      "RETURNED\tPROPN\tdobj\tBEEN\t103\n",
      ".\tPUNCT\tpunct\tBEEN\t103\n",
      "\n",
      "NO\tDET\tdet\tCONCLUSION\t107\n",
      "CONCLUSION\tNOUN\tnsubjpass\tDRAWN\t110\n",
      "CAN\tAUX\taux\tDRAWN\t110\n",
      "BE\tAUX\tauxpass\tDRAWN\t110\n",
      "DRAWN\tVERB\tROOT\tROOT\t110\n",
      "AT\tADP\tprep\tDRAWN\t110\n",
      "THIS\tDET\tdet\tTIME\t113\n",
      "TIME\tNOUN\tnpadvmod\tDRAWN\t110\n",
      ".\tPUNCT\tpunct\tDRAWN\t110\n",
      "\n",
      "WE\tPRON\tnsubj\tCONSIDER\t117\n",
      "THEREFORE\tADV\tadvmod\tCONSIDER\t117\n",
      "CONSIDER\tVERB\tROOT\tROOT\t117\n",
      "THIS\tDET\tdet\tREPORT\t119\n",
      "REPORT\tNOUN\tnsubj\tCOMPLETE\t120\n",
      "COMPLETE\tPROPN\tccomp\tCONSIDER\t117\n",
      "TO\tADP\tprep\tCOMPLETE\t120\n",
      "THE\tDET\tdet\tBEST\t123\n",
      "BEST\tNOUN\tpobj\tTO\t121\n",
      "OF\tADP\tprep\tBEST\t123\n",
      "OUR\tPRON\tposs\tKNOWLEDGE\t126\n",
      "KNOWLEDGE\tPROPN\tpobj\tOF\t124\n",
      ".\tPUNCT\tpunct\tCONSIDER\t117\n",
      "\n",
      "MEDTRONIC\tPROPN\tnsubj\tSUBMITTING\t136\n",
      ",\tPUNCT\tpunct\tMEDTRONIC\t128\n",
      "INC\tPROPN\tnpadvmod\tMEDTRONIC\t128\n",
      ".\tPROPN\tnpadvmod\tMEDTRONIC\t128\n",
      "(\tPUNCT\tpunct\t.\t131\n",
      "MEDTRONIC\tPROPN\tappos\t.\t131\n",
      ")\tPUNCT\tpunct\t.\t131\n",
      "IS\tAUX\taux\tSUBMITTING\t136\n",
      "SUBMITTING\tVERB\tROOT\tROOT\t136\n",
      "THIS\tDET\tdet\tREPORT\t138\n",
      "REPORT\tNOUN\tdobj\tSUBMITTING\t136\n",
      "TO\tADP\tprep\tSUBMITTING\t136\n",
      "COMPLY\tPROPN\tpobj\tTO\t139\n",
      "WITH\tADP\tprep\tSUBMITTING\t136\n",
      "21\tNUM\tnummod\tPART\t144\n",
      "C.F.R.\tPROPN\tcompound\tPART\t144\n",
      "PART\tPROPN\tpobj\tWITH\t141\n",
      "803\tNUM\tnummod\tPART\t144\n",
      ",\tPUNCT\tpunct\tSUBMITTING\t136\n",
      "THE\tDET\tdet\tDEVICE\t149\n",
      "MEDICAL\tPROPN\tcompound\tDEVICE\t149\n",
      "DEVICE\tNOUN\tdobj\tSUBMITTING\t136\n",
      "REPORTING\tVERB\tcompound\tREGULATION\t151\n",
      "REGULATION\tNOUN\tappos\tDEVICE\t149\n",
      ".\tPUNCT\tpunct\tSUBMITTING\t136\n",
      "\n",
      "THIS\tDET\tdet\tREPORT\t154\n",
      "REPORT\tNOUN\tnsubj\tIS\t155\n",
      "IS\tAUX\tROOT\tROOT\t155\n",
      "BASED\tVERB\tacomp\tIS\t155\n",
      "UPON\tPROPN\tcompound\tINFORMATION\t158\n",
      "INFORMATION\tPROPN\tnsubj\tOBTAINED\t159\n",
      "OBTAINED\tVERB\tccomp\tBASED\t156\n",
      "BY\tPROPN\tcompound\tMEDTRONIC\t161\n",
      "MEDTRONIC\tPROPN\tdobj\tOBTAINED\t159\n",
      ",\tPUNCT\tpunct\tMEDTRONIC\t161\n",
      "WHICH\tPRON\tdobj\tBEEN\t169\n",
      "THE\tDET\tdet\tCOMPANY\t165\n",
      "COMPANY\tNOUN\tnsubj\tBEEN\t169\n",
      "MAY\tAUX\taux\tBEEN\t169\n",
      "NOT\tPART\tneg\tBEEN\t169\n",
      "HAVE\tAUX\taux\tBEEN\t169\n",
      "BEEN\tAUX\trelcl\tMEDTRONIC\t161\n",
      "ABLE\tNOUN\tacomp\tBEEN\t169\n",
      "TO\tADP\tprep\tBEEN\t169\n",
      "FULLY\tADV\tadvmod\tINVESTIGATE\t173\n",
      "INVESTIGATE\tNOUN\tpobj\tTO\t171\n",
      "OR\tCCONJ\tcc\tINVESTIGATE\t173\n",
      "VERIFY\tPROPN\tcompound\tPRIOR\t176\n",
      "PRIOR\tNOUN\tconj\tINVESTIGATE\t173\n",
      "TO\tADP\tprep\tBEEN\t169\n",
      "THE\tDET\tdet\tDATE\t179\n",
      "DATE\tNOUN\tpobj\tTO\t177\n",
      "THE\tDET\tdet\tREPORT\t181\n",
      "REPORT\tPROPN\tnsubjpass\tREQUIRED\t183\n",
      "WAS\tAUX\tauxpass\tREQUIRED\t183\n",
      "REQUIRED\tVERB\trelcl\tDATE\t179\n",
      "BY\tADP\tagent\tREQUIRED\t183\n",
      "THE\tDET\tdet\tFDA\t186\n",
      "FDA\tPROPN\tpobj\tBY\t184\n",
      ".\tPUNCT\tpunct\tIS\t155\n",
      "\n",
      "MEDTRONIC\tPROPN\tnsubj\tMADE\t190\n",
      "HAS\tAUX\taux\tMADE\t190\n",
      "MADE\tVERB\tROOT\tROOT\t190\n",
      "REASONABLE\tADJ\tamod\tEFFORTS\t192\n",
      "EFFORTS\tNOUN\tdobj\tMADE\t190\n",
      "TO\tPART\taux\tOBTAIN\t194\n",
      "OBTAIN\tVERB\tadvcl\tMADE\t190\n",
      "MORE\tADJ\tadvmod\tCOMPLETE\t196\n",
      "COMPLETE\tPROPN\tcompound\tINFORMATION\t197\n",
      "INFORMATION\tNOUN\tdobj\tOBTAIN\t194\n",
      "IN\tADP\tprep\tOBTAIN\t194\n",
      "THE\tDET\tdet\tALLOTTED\t201\n",
      "TIME\tPROPN\tcompound\tALLOTTED\t201\n",
      "ALLOTTED\tPROPN\tpobj\tIN\t198\n",
      "AND\tCCONJ\tcc\tMADE\t190\n",
      "HAS\tAUX\taux\tPROVIDED\t204\n",
      "PROVIDED\tVERB\tconj\tMADE\t190\n",
      "AS\tADP\tprep\tPROVIDED\t204\n",
      "MUCH\tPROPN\tpobj\tAS\t205\n",
      "INFORMATION\tNOUN\tdobj\tPROVIDED\t204\n",
      "AS\tSCONJ\tmark\tIS\t209\n",
      "IS\tAUX\tadvcl\tPROVIDED\t204\n",
      "AVAILABLE\tNOUN\tnsubj\tIS\t209\n",
      "TO\tADP\tprep\tIS\t209\n",
      "THE\tDET\tdet\tCOMPANY\t213\n",
      "COMPANY\tPROPN\tpobj\tTO\t211\n",
      "AS\tADP\tprep\tPROVIDED\t204\n",
      "OF\tADP\tprep\tAS\t214\n",
      "THE\tDET\tdet\tDATE\t218\n",
      "SUBMISSION\tNOUN\tcompound\tDATE\t218\n",
      "DATE\tNOUN\tpobj\tOF\t215\n",
      "THIS\tDET\tdet\tREPORT\t220\n",
      "REPORT\tNOUN\tdobj\tPROVIDED\t204\n",
      ".\tPUNCT\tpunct\tMADE\t190\n",
      "\n",
      "THIS\tDET\tdet\tREPORT\t223\n",
      "REPORT\tNOUN\tnsubj\tCONSTITUTE\t226\n",
      "DOES\tAUX\taux\tCONSTITUTE\t226\n",
      "NOT\tPART\tneg\tCONSTITUTE\t226\n",
      "CONSTITUTE\tVERB\tROOT\tROOT\t226\n",
      "AN\tDET\tdet\tADMISSION\t228\n",
      "ADMISSION\tNOUN\tdobj\tCONSTITUTE\t226\n",
      "OR\tCCONJ\tcc\tCONSTITUTE\t226\n",
      "A\tDET\tdet\tCONCLUSION\t231\n",
      "CONCLUSION\tPROPN\tdobj\tCONSTITUTE\t226\n",
      "BY\tPROPN\tprep\tCONSTITUTE\t226\n",
      "FDA\tPROPN\tpobj\tBY\t232\n",
      ",\tPUNCT\tpunct\tFDA\t233\n",
      "MEDTRONIC\tPROPN\tconj\tFDA\t233\n",
      ",\tPUNCT\tpunct\tMEDTRONIC\t235\n",
      "OR\tCCONJ\tcc\tCONSTITUTE\t226\n",
      "ITS\tPRON\tposs\tEMPLOYEES\t239\n",
      "EMPLOYEES\tNOUN\tnsubj\tDESCRIBED\t255\n",
      "THAT\tSCONJ\tmark\tCONTRIBUTED\t251\n",
      "THE\tDET\tdet\tDEVICE\t242\n",
      "DEVICE\tNOUN\tnsubj\tCONTRIBUTED\t251\n",
      ",\tPUNCT\tpunct\tDEVICE\t242\n",
      "MEDTRONIC\tPROPN\tappos\tDEVICE\t242\n",
      ",\tPUNCT\tpunct\tMEDTRONIC\t244\n",
      "OR\tCCONJ\tcc\tDEVICE\t242\n",
      "ITS\tPRON\tposs\tEMPLOYEES\t248\n",
      "EMPLOYEES\tPROPN\tnsubj\tCAUSED\t249\n",
      "CAUSED\tNOUN\tconj\tDEVICE\t242\n",
      "OR\tCCONJ\tcc\tCAUSED\t249\n",
      "CONTRIBUTED\tVERB\tacl\tEMPLOYEES\t239\n",
      "TO\tADP\tprep\tCONTRIBUTED\t251\n",
      "THE\tDET\tdet\tEVENT\t254\n",
      "EVENT\tNOUN\tpobj\tTO\t252\n",
      "DESCRIBED\tVERB\tconj\tCONSTITUTE\t226\n",
      "IN\tADP\tprep\tDESCRIBED\t255\n",
      "THE\tDET\tdet\tREPORT\t258\n",
      "REPORT\tPROPN\tpobj\tIN\t256\n",
      ".\tPUNCT\tpunct\tCONSTITUTE\t226\n",
      "\n",
      "IN\tADP\tprep\tCONSTITUTE\t267\n",
      "PARTICULAR\tPROPN\tpobj\tIN\t260\n",
      ",\tPUNCT\tpunct\tCONSTITUTE\t267\n",
      "THIS\tDET\tdet\tREPORT\t264\n",
      "REPORT\tNOUN\tnsubj\tCONSTITUTE\t267\n",
      "DOES\tAUX\taux\tCONSTITUTE\t267\n",
      "NOT\tPART\tneg\tCONSTITUTE\t267\n",
      "CONSTITUTE\tVERB\tROOT\tROOT\t267\n",
      "AN\tDET\tdet\tADMISSION\t269\n",
      "ADMISSION\tNOUN\tdobj\tCONSTITUTE\t267\n",
      "BY\tADP\tprep\tCONSTITUTE\t267\n",
      "ANYONE\tPRON\tpobj\tBY\t270\n",
      "THAT\tSCONJ\tdobj\tDESCRIBED\t275\n",
      "THE\tDET\tdet\tPRODUCT\t274\n",
      "PRODUCT\tNOUN\tnsubj\tDESCRIBED\t275\n",
      "DESCRIBED\tVERB\tccomp\tCONSTITUTE\t267\n",
      "IN\tADP\tprep\tDESCRIBED\t275\n",
      "THIS\tDET\tdet\tREPORT\t278\n",
      "REPORT\tNOUN\tpobj\tIN\t276\n",
      "HAS\tVERB\tadvcl\tCONSTITUTE\t267\n",
      "ANY\tDET\tdet\tOR\t284\n",
      "\"\tPUNCT\tpunct\tOR\t284\n",
      "DEFECTS\tNOUN\tnmod\tOR\t284\n",
      "\"\tPUNCT\tpunct\tDEFECTS\t282\n",
      "OR\tNOUN\tcc\tCONSTITUTE\t267\n",
      "HAS\tAUX\taux\tMALFUNCTIONED\t287\n",
      "\"\tPUNCT\tpunct\tMALFUNCTIONED\t287\n",
      "MALFUNCTIONED\tPROPN\tconj\tCONSTITUTE\t267\n",
      "\"\tPUNCT\tpunct\tMALFUNCTIONED\t287\n",
      ".\tPUNCT\tpunct\tCONSTITUTE\t267\n",
      "\n",
      "THESE\tDET\tdet\tWORDS\t291\n",
      "WORDS\tNOUN\tnsubjpass\tINCLUDED\t293\n",
      "ARE\tAUX\tauxpass\tINCLUDED\t293\n",
      "INCLUDED\tVERB\tROOT\tROOT\t293\n",
      "IN\tADP\tprep\tINCLUDED\t293\n",
      "THE\tDET\tdet\tFORM\t298\n",
      "FDA\tPROPN\tcompound\tFORM\t298\n",
      "3500A\tPROPN\tcompound\tFORM\t298\n",
      "FORM\tPROPN\tpobj\tIN\t294\n",
      "AND\tCCONJ\tcc\tINCLUDED\t293\n",
      "ARE\tAUX\tauxpass\tFIXED\t301\n",
      "FIXED\tVERB\tconj\tINCLUDED\t293\n",
      "ITEMS\tNOUN\toprd\tFIXED\t301\n",
      "FOR\tADP\tprep\tFIXED\t301\n",
      "SELECTION\tNOUN\tpobj\tFOR\t303\n",
      "CREATED\tVERB\tacl\tSELECTION\t304\n",
      "BY\tADP\tagent\tCREATED\t305\n",
      "THE\tDET\tdet\tFDA\t308\n",
      "FDA\tPROPN\tpobj\tBY\t306\n",
      ",\tPUNCT\tpunct\tFIXED\t301\n",
      "TO\tPART\taux\tCATEGORIZE\t311\n",
      "CATEGORIZE\tVERB\tadvcl\tFIXED\t301\n",
      "THE\tDET\tdet\tTYPE\t313\n",
      "TYPE\tNOUN\tdobj\tCATEGORIZE\t311\n",
      "OF\tADP\tprep\tTYPE\t313\n",
      "EVENT\tNOUN\tpobj\tOF\t314\n",
      "SOLELY\tPROPN\tnpadvmod\tFIXED\t301\n",
      "FOR\tADP\tprep\tFIXED\t301\n",
      "THE\tDET\tdet\tPURPOSE\t319\n",
      "PURPOSE\tNOUN\tpobj\tFOR\t317\n",
      "OF\tADP\tprep\tPURPOSE\t319\n",
      "REPORTING\tVERB\tcompound\tPURSUANT\t322\n",
      "PURSUANT\tNOUN\tpobj\tOF\t320\n",
      "TO\tADP\tprep\tFIXED\t301\n",
      "PART\tPROPN\tpobj\tTO\t323\n",
      "803\tNUM\tnummod\tPART\t324\n",
      ".\tPUNCT\tpunct\tINCLUDED\t293\n",
      "\n",
      "MEDTRONIC\tPROPN\tcompound\tOBJECTS\t328\n",
      "OBJECTS\tPROPN\tnsubj\tIMPLIED\t348\n",
      "TO\tADP\tprep\tOBJECTS\t328\n",
      "THE\tDET\tdet\tUSE\t331\n",
      "USE\tNOUN\tpobj\tTO\t329\n",
      "OF\tADP\tprep\tUSE\t331\n",
      "THESE\tDET\tdet\tWORDS\t334\n",
      "WORDS\tNOUN\tpobj\tOF\t332\n",
      "AND\tCCONJ\tcc\tWORDS\t334\n",
      "OTHERS\tNOUN\tconj\tWORDS\t334\n",
      "LIKE\tADP\tprep\tOBJECTS\t328\n",
      "IT\tPRON\tdobj\tLIKE\t337\n",
      "BECAUSE\tSCONJ\tprep\tOBJECTS\t328\n",
      "OF\tADP\tpcomp\tBECAUSE\t339\n",
      "THE\tDET\tdet\tLACK\t342\n",
      "LACK\tNOUN\tpobj\tBECAUSE\t339\n",
      "OF\tADP\tprep\tLACK\t342\n",
      "DEFINITION\tNOUN\tpobj\tOF\t343\n",
      "AND\tCCONJ\tcc\tLACK\t342\n",
      "THE\tDET\tdet\tCONNOTATIONS\t347\n",
      "CONNOTATIONS\tPROPN\tconj\tLACK\t342\n",
      "IMPLIED\tPROPN\tROOT\tROOT\t348\n",
      "BY\tADP\tprep\tIMPLIED\t348\n",
      "THESE\tDET\tdet\tTERMS\t351\n",
      "TERMS\tPROPN\tpobj\tBY\t349\n",
      ".\tPUNCT\tpunct\tIMPLIED\t348\n",
      "\n",
      "THIS\tDET\tdet\tSTATEMENT\t354\n",
      "STATEMENT\tPROPN\tnsubjpass\tINCLUDED\t357\n",
      "SHOULD\tAUX\taux\tINCLUDED\t357\n",
      "BE\tAUX\tauxpass\tINCLUDED\t357\n",
      "INCLUDED\tVERB\tROOT\tROOT\t357\n",
      "WITH\tADP\tprep\tINCLUDED\t357\n",
      "ANY\tDET\tdet\tINFORMATION\t360\n",
      "INFORMATION\tNOUN\tpobj\tWITH\t358\n",
      "OR\tCCONJ\tcc\tINFORMATION\t360\n",
      "REPORT\tPROPN\tnsubj\tDISCLOSED\t363\n",
      "DISCLOSED\tVERB\tconj\tINCLUDED\t357\n",
      "TO\tADP\tprep\tDISCLOSED\t363\n",
      "THE\tDET\tdet\tPUBLIC\t366\n",
      "PUBLIC\tNOUN\tpobj\tTO\t364\n",
      "UNDER\tADP\tprep\tDISCLOSED\t363\n",
      "THE\tDET\tdet\tFREEDOM\t369\n",
      "FREEDOM\tNOUN\tpobj\tUNDER\t367\n",
      "OF\tADP\tprep\tFREEDOM\t369\n",
      "INFORMATION\tPROPN\tcompound\tACT\t372\n",
      "ACT\tPROPN\tpobj\tOF\t370\n",
      ".\tPUNCT\tpunct\tINCLUDED\t357\n",
      "\n",
      "A\tDET\tdet\tPATIENT\t380\n",
      "PERITONEAL\tPROPN\tnmod\tPATIENT\t380\n",
      "DIALYSIS\tPROPN\tnmod\tPATIENT\t380\n",
      "(\tPUNCT\tpunct\tPATIENT\t380\n",
      "PD\tPROPN\tnmod\tPATIENT\t380\n",
      ")\tPUNCT\tpunct\tPATIENT\t380\n",
      "PATIENT\tNOUN\tnsubj\tEXPERIENCED\t381\n",
      "EXPERIENCED\tVERB\tROOT\tROOT\t381\n",
      "FIVE\tNUM\tnummod\tEPISODES\t383\n",
      "EPISODES\tPROPN\tdobj\tEXPERIENCED\t381\n",
      "OF\tADP\tprep\tEPISODES\t383\n",
      "PERITONITIS\tPROPN\tpobj\tOF\t384\n",
      ".\tPUNCT\tpunct\tEXPERIENCED\t381\n",
      "\n",
      "THE\tDET\tdet\tPERITONITIS\t391\n",
      "\"\tPUNCT\tpunct\tPERITONITIS\t391\n",
      "FIFTH\tPROPN\tnmod\tPERITONITIS\t391\n",
      "\"\tPUNCT\tpunct\tPERITONITIS\t391\n",
      "PERITONITIS\tPROPN\tnsubj\tWAS\t392\n",
      "WAS\tAUX\tROOT\tROOT\t392\n",
      "CONFIRMED\tADJ\tacomp\tWAS\t392\n",
      "TO\tPART\taux\tBE\t395\n",
      "BE\tAUX\txcomp\tCONFIRMED\t393\n",
      "ENCAPSULATED\tVERB\tamod\tPERITONITIS\t398\n",
      "SCLEROSING\tPROPN\tcompound\tPERITONITIS\t398\n",
      "PERITONITIS\tPROPN\tattr\tBE\t395\n",
      ".\tPUNCT\tpunct\tWAS\t392\n",
      "\n",
      "ON\tADP\tprep\tWAS\t411\n",
      "THE\tDET\tdet\tDAY\t403\n",
      "SAME\tADJ\tamod\tDAY\t403\n",
      "DAY\tNOUN\tpobj\tON\t400\n",
      "AS\tADP\tprep\tWAS\t411\n",
      "THE\tDET\tdet\tEVENT\t406\n",
      "EVENT\tPROPN\tnsubj\tONSET\t407\n",
      "ONSET\tNOUN\tpobj\tAS\t404\n",
      ",\tPUNCT\tpunct\tWAS\t411\n",
      "THE\tDET\tdet\tPATIENT\t410\n",
      "PATIENT\tNOUN\tnsubj\tWAS\t411\n",
      "WAS\tAUX\tROOT\tROOT\t411\n",
      "HOSPITALIZED\tNOUN\tattr\tWAS\t411\n",
      "FOR\tADP\tprep\tWAS\t411\n",
      "THE\tDET\tdet\tEVENT\t415\n",
      "EVENT\tNOUN\tpobj\tFOR\t413\n",
      ".\tPUNCT\tpunct\tWAS\t411\n",
      "\n",
      "PD\tPROPN\tcompound\tCATHETER\t418\n",
      "CATHETER\tPROPN\tnsubj\tWAS\t419\n",
      "WAS\tAUX\tROOT\tROOT\t419\n",
      "REMOVED\tPROPN\tacomp\tWAS\t419\n",
      "WITHIN\tADP\tprep\tWAS\t419\n",
      "A\tDET\tdet\tDAY\t423\n",
      "DAY\tPROPN\tpobj\tWITHIN\t421\n",
      "OR\tCCONJ\tcc\tWAS\t419\n",
      "2\tNUM\tnummod\tOR\t424\n",
      "OF\tADP\tprep\tWAS\t419\n",
      "HOSPITAL\tNOUN\tcompound\tADMISSION\t428\n",
      "ADMISSION\tNOUN\tpobj\tOF\t426\n",
      "AND\tCCONJ\tcc\tWAS\t419\n",
      "WITHDREW\tVERB\tconj\tWAS\t419\n",
      "FROM\tADP\tprep\tWITHDREW\t430\n",
      "TREATMENT\tPROPN\tpobj\tFROM\t431\n",
      ".\tPUNCT\tpunct\tWAS\t419\n",
      "\n",
      "THE\tDET\tdet\tCAUSE\t435\n",
      "CAUSE\tNOUN\tnmod\tOUTCOME\t440\n",
      ",\tPUNCT\tpunct\tCAUSE\t435\n",
      "TREATMENT\tPROPN\tconj\tCAUSE\t435\n",
      "AND\tCCONJ\tcc\tTREATMENT\t437\n",
      "PATIENT\tPROPN\tconj\tTREATMENT\t437\n",
      "OUTCOME\tPROPN\tnsubjpass\tREPORTED\t443\n",
      "WERE\tAUX\tauxpass\tREPORTED\t443\n",
      "NOT\tPART\tneg\tREPORTED\t443\n",
      "REPORTED\tVERB\tROOT\tROOT\t443\n",
      ".\tPUNCT\tpunct\tREPORTED\t443\n",
      "\n",
      "AFTER\tADP\tprep\tDISCHARGE\t447\n",
      "HOSPITAL\tNOUN\tpobj\tAFTER\t445\n",
      "DISCHARGE\tVERB\tadvcl\tPASSED\t462\n",
      "16\tNUM\tnummod\tDAYS\t449\n",
      "DAYS\tNOUN\tnpadvmod\tAFTER\t450\n",
      "AFTER\tADP\tprep\tDISCHARGE\t447\n",
      "THE\tDET\tdet\tONSET\t452\n",
      "ONSET\tNOUN\tpobj\tAFTER\t450\n",
      "OF\tADP\tprep\tONSET\t452\n",
      "THE\tDET\tdet\tPERITONITIS\t458\n",
      "\"\tPUNCT\tpunct\tPERITONITIS\t458\n",
      "FIFTH\tPROPN\tnmod\tPERITONITIS\t458\n",
      "\"\tPUNCT\tpunct\tPERITONITIS\t458\n",
      "PERITONITIS\tPROPN\tpobj\tOF\t453\n",
      ",\tPUNCT\tpunct\tPASSED\t462\n",
      "THE\tDET\tdet\tPATIENT\t461\n",
      "PATIENT\tNOUN\tnsubj\tPASSED\t462\n",
      "PASSED\tVERB\tROOT\tROOT\t462\n",
      "AWAY\tADV\tadvmod\tPASSED\t462\n",
      ".\tPUNCT\tpunct\tPASSED\t462\n",
      "\n",
      "THE\tDET\tdet\tCAUSE\t466\n",
      "CAUSE\tPROPN\tnsubjpass\tREPORTED\t470\n",
      "OF\tADP\tprep\tCAUSE\t466\n",
      "DEATH\tNOUN\tpobj\tOF\t467\n",
      "WAS\tAUX\tauxpass\tREPORTED\t470\n",
      "REPORTED\tVERB\tROOT\tROOT\t470\n",
      "AS\tADP\tprep\tREPORTED\t470\n",
      "DUE\tPROPN\tpcomp\tAS\t471\n",
      "TO\tADP\tpcomp\tDUE\t472\n",
      "THE\tDET\tdet\tPATIENT\t475\n",
      "PATIENT\tNOUN\tpobj\tAS\t471\n",
      "WITHDREW\tVERB\tadvcl\tREPORTED\t470\n",
      "FROM\tADP\tprep\tWITHDREW\t476\n",
      "TREATMENT\tPROPN\tpobj\tFROM\t477\n",
      "\n",
      "AS\tSCONJ\tmark\tWANT\t484\n",
      "THE\tDET\tdet\tPATIENT\t481\n",
      "PATIENT\tNOUN\tnsubj\tWANT\t484\n",
      "DID\tAUX\taux\tWANT\t484\n",
      "NOT\tPART\tneg\tWANT\t484\n",
      "WANT\tVERB\tROOT\tROOT\t484\n",
      "TO\tPART\taux\tTRANSITION\t486\n",
      "TRANSITION\tVERB\txcomp\tWANT\t484\n",
      "ONTO\tNOUN\tcompound\tLIFE\t488\n",
      "LIFE\tNOUN\tdobj\tTRANSITION\t486\n",
      "OF\tADP\tprep\tLIFE\t488\n",
      "HEMODIALYSIS\tPROPN\tpobj\tOF\t489\n",
      ".\tPUNCT\tpunct\tWANT\t484\n",
      "\n",
      "AUTOPSY\tPROPN\tnsubj\tWAS\t493\n",
      "WAS\tAUX\tROOT\tROOT\t493\n",
      "NOT\tPART\tneg\tPERFORMED\t495\n",
      "PERFORMED\tADJ\tacomp\tWAS\t493\n",
      ".\tPUNCT\tpunct\tWAS\t493\n",
      "\n",
      "IT\tPRON\tnsubjpass\tREPORTED\t500\n",
      "WAS\tAUX\tauxpass\tREPORTED\t500\n",
      "NOT\tPART\tneg\tREPORTED\t500\n",
      "REPORTED\tVERB\tROOT\tROOT\t500\n",
      "IF\tSCONJ\tmark\tRECOVERED\t505\n",
      "THE\tDET\tdet\tPATIENT\t503\n",
      "PATIENT\tNOUN\tnsubj\tRECOVERED\t505\n",
      "HAS\tAUX\taux\tRECOVERED\t505\n",
      "RECOVERED\tVERB\tadvcl\tREPORTED\t500\n",
      "FROM\tADP\tprep\tRECOVERED\t505\n",
      "THE\tDET\tdet\tPERITONITIS\t508\n",
      "PERITONITIS\tPROPN\tpobj\tFROM\t506\n",
      "EVENT\tVERB\tccomp\tREPORTED\t500\n",
      "PRIOR\tPROPN\tdobj\tEVENT\t509\n",
      "TO\tADP\tprep\tEVENT\t509\n",
      "OR\tCCONJ\tcc\tTO\t511\n",
      "AT\tADP\tprep\tREPORTED\t500\n",
      "THE\tDET\tdet\tTIME\t515\n",
      "TIME\tPROPN\tpobj\tAT\t513\n",
      "OF\tADP\tprep\tTIME\t515\n",
      "DEATH\tNOUN\tpobj\tOF\t516\n",
      ".\tPUNCT\tpunct\tREPORTED\t500\n",
      "\n",
      "NO\tDET\tdet\tINFORMATION\t521\n",
      "ADDITIONAL\tADJ\tamod\tINFORMATION\t521\n",
      "INFORMATION\tNOUN\tnsubj\tIS\t522\n",
      "IS\tAUX\tROOT\tROOT\t522\n",
      "AVAILABLE\tPROPN\tattr\tIS\t522\n",
      ".\tPUNCT\tpunct\tIS\t522\n",
      "\n",
      "THE\tDET\tdet\tDEVICE\t526\n",
      "DEVICE\tNOUN\tnsubj\tWAS\t527\n",
      "WAS\tAUX\tauxpass\tCOMPLETED\t545\n",
      "NOT\tPART\tneg\tWAS\t527\n",
      "RETURNED\tPROPN\tattr\tWAS\t527\n",
      "AND\tCCONJ\tcc\tRETURNED\t529\n",
      "THE\tDET\tdet\tNUMBER\t533\n",
      "LOT\tPROPN\tcompound\tNUMBER\t533\n",
      "NUMBER\tNOUN\tnsubj\tIS\t534\n",
      "IS\tAUX\tccomp\tCOMPLETED\t545\n",
      "UNKNOWN\tADJ\tacomp\tIS\t534\n",
      ";\tPUNCT\tpunct\tCOMPLETED\t545\n",
      "THEREFORE\tPROPN\tadvmod\tCOMPLETED\t545\n",
      ",\tPUNCT\tpunct\tCOMPLETED\t545\n",
      "A\tDET\tdet\tDEVICE\t540\n",
      "DEVICE\tNOUN\tnsubjpass\tCOMPLETED\t545\n",
      "ANALYSIS\tNOUN\tappos\tDEVICE\t540\n",
      "COULD\tAUX\taux\tCOMPLETED\t545\n",
      "NOT\tPART\tneg\tCOMPLETED\t545\n",
      "BE\tAUX\tauxpass\tCOMPLETED\t545\n",
      "COMPLETED\tVERB\tROOT\tROOT\t545\n",
      ".\tPUNCT\tpunct\tCOMPLETED\t545\n",
      "\n",
      "SHOULD\tAUX\taux\tADDITIONAL\t548\n",
      "ADDITIONAL\tVERB\tadvcl\tSUBMITTED\t559\n",
      "RELEVANT\tADJ\tamod\tINFORMATION\t550\n",
      "INFORMATION\tNOUN\tnsubj\tBECOME\t551\n",
      "BECOME\tVERB\tccomp\tADDITIONAL\t548\n",
      "AVAILABLE\tPROPN\tdobj\tBECOME\t551\n",
      ",\tPUNCT\tpunct\tSUBMITTED\t559\n",
      "A\tDET\tdet\tREPORT\t556\n",
      "SUPPLEMENTAL\tPROPN\tcompound\tREPORT\t556\n",
      "REPORT\tPROPN\tnsubjpass\tSUBMITTED\t559\n",
      "WILL\tAUX\taux\tSUBMITTED\t559\n",
      "BE\tAUX\tauxpass\tSUBMITTED\t559\n",
      "SUBMITTED\tVERB\tROOT\tROOT\t559\n",
      ".\tPUNCT\tpunct\tSUBMITTED\t559\n",
      "\n",
      "IT\tPRON\tnsubjpass\tREPORTED\t563\n",
      "WAS\tAUX\tauxpass\tREPORTED\t563\n",
      "REPORTED\tVERB\tROOT\tROOT\t563\n",
      "THAT\tDET\tdet\tPOST\t565\n",
      "POST\tPROPN\tnsubj\tEXHIBITED\t574\n",
      "IMPLANT\tADJ\tappos\tPOST\t565\n",
      "THE†LEADLESS\tPROPN\tcompound\tGENERATOR\t570\n",
      "IMPLANTABLE\tPROPN\tcompound\tPULSE\t569\n",
      "PULSE\tPROPN\tcompound\tGENERATOR\t570\n",
      "GENERATOR\tPROPN\tappos\tPOST\t565\n",
      "(\tPUNCT\tpunct\tIPG\t572\n",
      "IPG\tPROPN\tappos\tGENERATOR\t570\n",
      ")\tPUNCT\tpunct\tGENERATOR\t570\n",
      "EXHIBITED\tVERB\tccomp\tREPORTED\t563\n",
      "HIGH\tADJ\tamod\tTHRESHOLDS\t576\n",
      "THRESHOLDS\tNOUN\tdobj\tEXHIBITED\t574\n",
      "AND\tCCONJ\tcc\tTHRESHOLDS\t576\n",
      "INTERMITTENT\tADJ\tdet\tCAPTURE\t579\n",
      "CAPTURE\tNOUN\tconj\tTHRESHOLDS\t576\n",
      "WITH\tADP\tprep\tCAPTURE\t579\n",
      "THE\tDET\tdet\tPATIENTS\t582\n",
      "PATIENTS\tNOUN\tpobj\tWITH\t580\n",
      "QRS\tPROPN\tcompound\tWIDENING\t584\n",
      "WIDENING\tPROPN\tpobj\tWITH\t580\n",
      ".\tPUNCT\tpunct\tREPORTED\t563\n",
      "\n",
      "THE\tDET\tdet\tDEVICE\t587\n",
      "DEVICE\tNOUN\tnsubj\tWAS\t588\n",
      "WAS\tAUX\tROOT\tROOT\t588\n",
      "REPOSITIONED\tNOUN\tattr\tWAS\t588\n",
      "AND\tCCONJ\tcc\tREPOSITIONED\t589\n",
      "REPROGRAMMED\tPROPN\tcompound\tHOWEVER\t592\n",
      "HOWEVER\tPROPN\tadvmod\tDEVELOPED\t596\n",
      ",\tPUNCT\tpunct\tDEVELOPED\t596\n",
      "THE\tDET\tdet\tPATIENT\t595\n",
      "PATIENT\tNOUN\tnsubj\tDEVELOPED\t596\n",
      "DEVELOPED\tVERB\tconj\tWAS\t588\n",
      "METABOLIC\tPROPN\tcompound\tLOSS\t600\n",
      "ACIDOSIS\tPROPN\tcompound\tCAUSING\t599\n",
      "CAUSING\tPROPN\tcompound\tLOSS\t600\n",
      "LOSS\tNOUN\tdobj\tDEVELOPED\t596\n",
      "OF\tADP\tprep\tLOSS\t600\n",
      "CAPTURE\tPROPN\tpobj\tOF\t601\n",
      ".\tPUNCT\tpunct\tDEVELOPED\t596\n",
      "\n",
      "THE\tDET\tdet\tPATIENT\t605\n",
      "PATIENT\tNOUN\tnsubj\tCODED\t607\n",
      "THEN\tADV\tadvmod\tCODED\t607\n",
      "CODED\tNOUN\tROOT\tROOT\t607\n",
      "AND\tCCONJ\tcc\tCODED\t607\n",
      "PASSED\tVERB\tconj\tCODED\t607\n",
      "AWAY\tADV\tadvmod\tPASSED\t609\n",
      ".\tPUNCT\tpunct\tCODED\t607\n",
      "\n",
      "POS tags have been saved to pos_5.txt\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    process_sentences_with_heads(input_file, pos_file)\n",
    "    print(f\"POS tags have been saved to {pos_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGJERY-w1Nsn"
   },
   "source": [
    "# 3. POS to Neo4j Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1740348200811,
     "user": {
      "displayName": "Julie Cheng",
      "userId": "04885444118924469249"
     },
     "user_tz": 300
    },
    "id": "kRxWgPJ5oLJ_"
   },
   "outputs": [],
   "source": [
    "def generate_neo4j_queries(pos_file, output_file):\n",
    "    # Read enhanced POS file\n",
    "    with open(pos_file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Skip header and separator\n",
    "    lines = [line.strip() for line in lines[2:]]\n",
    "\n",
    "    queries = []\n",
    "    sentence_counter = 1\n",
    "    token_counter = 0  # Global counter for token IDs\n",
    "    sentence_start_indices = {}  # Store starting index for each sentence\n",
    "\n",
    "    # Add constraints\n",
    "    queries.append(\"// Create constraints\")\n",
    "    queries.append(\"CREATE CONSTRAINT IF NOT EXISTS FOR (w:Token) REQUIRE w.id IS UNIQUE;\")\n",
    "    queries.append(\"\")\n",
    "\n",
    "    # First pass: collect sentence start indices\n",
    "    current_tokens = []\n",
    "    for line in lines + [\"\"]:  # Append empty line to process the last sentence\n",
    "        if not line:  # Sentence boundary\n",
    "            if current_tokens:\n",
    "                sentence_start_indices[sentence_counter] = token_counter\n",
    "                token_counter += len(current_tokens)\n",
    "                current_tokens = []\n",
    "                sentence_counter += 1\n",
    "        else:\n",
    "            current_tokens.append(line)\n",
    "\n",
    "    # Reset counters for second pass\n",
    "    sentence_counter = 1\n",
    "    token_counter = 0\n",
    "    current_sentence = []\n",
    "\n",
    "    # Second pass: generate queries\n",
    "    for line in lines + [\"\"]:\n",
    "        if not line:  # Sentence boundary\n",
    "            if current_sentence:\n",
    "                queries.extend(create_dependency_queries(current_sentence, sentence_counter, sentence_start_indices))\n",
    "                queries.append(\"\")\n",
    "                token_counter += len(current_sentence)\n",
    "                sentence_counter += 1\n",
    "                current_sentence = []\n",
    "        else:\n",
    "            try:\n",
    "                token, pos, dep, head_token, head_idx = line.split('\\t')\n",
    "                current_sentence.append((token, pos, dep, head_token, int(head_idx)))\n",
    "            except ValueError:\n",
    "                print(f\"Skipping malformed line: {line}\")\n",
    "\n",
    "    # End of Schema\n",
    "    queries.append(\"// This is end of schema.\")\n",
    "\n",
    "    # Write queries to file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(queries))\n",
    "\n",
    "def create_dependency_queries(sentence_tokens, sentence_num, sentence_start_indices):\n",
    "    queries = []\n",
    "    start_idx = sentence_start_indices.get(sentence_num, 0)\n",
    "\n",
    "    # Create token nodes\n",
    "    queries.append(f\"// Create tokens for sentence {sentence_num}\")\n",
    "    create_tokens = []\n",
    "    for i, (token, pos, dep, _, _) in enumerate(sentence_tokens):\n",
    "        token_id = start_idx + i\n",
    "        token = token.replace(\"'\", \"\\\\'\")  # Escape single quotes\n",
    "        create_tokens.append(\n",
    "            f\"(t{token_id}:Token {{id: {token_id}, text: '{token}', pos: '{pos}', position: {i}}})\"\n",
    "        )\n",
    "\n",
    "    queries.append(\"CREATE \" + \",\\n       \".join(create_tokens))\n",
    "    queries.append(f\"WITH [{', '.join(f't{start_idx + i}' for i in range(len(sentence_tokens)))}] as nodes\")\n",
    "\n",
    "    # Create dependency relationships\n",
    "    queries.append(f\"// Create dependency relationships for sentence {sentence_num}\")\n",
    "    for i, (_, _, dep, _, head_idx) in enumerate(sentence_tokens):\n",
    "        curr_id = start_idx + i\n",
    "\n",
    "        if curr_id != head_idx and head_idx >= 0:\n",
    "            queries.append(\n",
    "                f\"MATCH (t1:Token {{id: {curr_id}}}), (t2:Token {{id: {head_idx}}}) WITH t1, t2 CREATE (t1)-[:{dep}]->(t2);\"\n",
    "            )\n",
    "\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1740349904757,
     "user": {
      "displayName": "Julie Cheng",
      "userId": "04885444118924469249"
     },
     "user_tz": 300
    },
    "id": "q0epqDD-7djO",
    "outputId": "6b41956b-3e87-43ce-d917-f677301ba97a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4j queries have been saved to neo4j_pos_5.cypher\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_e9f67b5e-d2f5-416b-ac43-ee99bbddf2c5\", \"neo4j_pos_5.cypher\", 101863)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    generate_neo4j_queries(pos_file, output_file)\n",
    "    print(f\"Neo4j queries have been saved to {output_file}\")\n",
    "\n",
    "    # For Colab: Enable file download\n",
    "    from google.colab import files\n",
    "    files.download(output_file)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2rGQTKQ2Pl3"
   },
   "source": [
    "# 4. Execute Schema in Neo4j (Done in Neo4j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKwXebt92Rsb"
   },
   "source": [
    "## Set up and tutorials\n",
    "1. Download Neo4j app.\n",
    "2. Open a Neo4j DBMS in Browser. You can use Example Project Movie DBMS.\n",
    "3. Movie Graph tutorial is a good one to begin with Neo4j."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Og_T9iz3S9P"
   },
   "source": [
    "## Import Schema into Neo4j\n",
    "1. Clean up: Before we create our database, we might need to clean up original graph (especially if you test the schema on Movie DBMS). Execute the following command to remove existing graph.\n",
    "\n",
    "    ```\n",
    "    MATCH (n) DETACH DELETE n;\n",
    "    ```\n",
    "\n",
    "2. Import our schema: Copy all the content in .cypher we get from step 3 and execute. This step creates a graph based on our schema in Neo4j.\n",
    "\n",
    "3. Visualize our graph: Execute the following command to visualize the graph. If the grpah is too big, add limit to the command, in the example command, the number of nodes is limited by 25.\n",
    "\n",
    "    ```\n",
    "    MATCH (n) RETURN n;\n",
    "    # or\n",
    "    MATCH (n) RETURN n LIMIT 25;\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhTJuSW2Rl51"
   },
   "source": [
    "# Reference\n",
    "- Download Neo4j Desktop: https://neo4j.com/download/\n",
    "- Spacy 101: https://spacy.io/usage/spacy-101\n",
    "- https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/13-POS-Keywords.html"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPhof3ZXH49h15JUONqGuFD",
   "mount_file_id": "1kgThJZbAF2UBhmkCyJlUNwCxBxBoLLKX",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
